{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import yaml\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.preprocessing.text_cleaner import TextCleaner\n",
    "from src.sentiment.bert_classifier import SentimentAnalyzer\n",
    "from src.topic.topic_modeling import TopicModeling\n",
    "from src.keywords.keyword_extractor import KeywordExtractor\n",
    "from src.evolution.evolution_analyzer import EvolutionAnalyzer\n",
    "from src.visualization.dashboard import Dashboard\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, config_path: str = 'config/config.yaml'):\n",
    "        \"\"\"\n",
    "        初始化Pipeline\n",
    "        Args:\n",
    "            config_path: 配置文件路径\n",
    "        \"\"\"\n",
    "        self.config = self._load_config(config_path)\n",
    "        self.text_cleaner = TextCleaner(\n",
    "            stopwords_path=self.config['preprocessing']['stopwords_path']\n",
    "        )\n",
    "        self.sentiment_analyzer = SentimentAnalyzer(\n",
    "            model_path=self.config['sentiment']['model_path']\n",
    "        )\n",
    "        self.topic_modeling = TopicModeling(\n",
    "            min_topics=self.config['topic']['min_topics'],\n",
    "            max_topics=self.config['topic']['max_topics']\n",
    "        )\n",
    "        self.keyword_extractor = KeywordExtractor(\n",
    "            top_k=self.config['keywords']['top_k']\n",
    "        )\n",
    "        self.evolution_analyzer = EvolutionAnalyzer()\n",
    "        \n",
    "        self.processed_data = None\n",
    "        self.sentiment_results = None\n",
    "        self.topic_results = None\n",
    "        self.keyword_results = None\n",
    "        self.evolution_results = None\n",
    "    \n",
    "    def _load_config(self, config_path: str) -> Dict:\n",
    "        \"\"\"加载配置文件\"\"\"\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            return yaml.safe_load(f)\n",
    "    \n",
    "    def load_data(self, data_path: str) -> pd.DataFrame:\n",
    "        \"\"\"加载数据\"\"\"\n",
    "        logger.info(f\"正在加载数据: {data_path}\")\n",
    "        # 只读取前200行数据用于测试\n",
    "        return pd.read_csv(data_path).head(50)\n",
    "    \n",
    "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"数据预处理\"\"\"\n",
    "        logger.info(\"开始数据预处理...\")\n",
    "        processed_df = self.text_cleaner.process_dataframe(df)\n",
    "        self.processed_data = processed_df\n",
    "        return processed_df\n",
    "    \n",
    "    def analyze_sentiment(self) -> Tuple[List[int], List[float]]:\n",
    "        \"\"\"情感分析\"\"\"\n",
    "        logger.info(\"开始情感分析...\")\n",
    "        texts = self.processed_data['cleaned_text'].tolist()\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        for text in tqdm(texts, desc=\"情感分析进度\"):\n",
    "            pred, prob = self.sentiment_analyzer.predict([text])\n",
    "            predictions.extend(pred)\n",
    "            probabilities.extend(prob)\n",
    "            \n",
    "        # 将情感分析结果保存到数据框中\n",
    "        self.processed_data['sentiment'] = predictions\n",
    "        self.processed_data['sentiment_probability'] = probabilities\n",
    "            \n",
    "        self.sentiment_results = (predictions, probabilities)\n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def analyze_topics(self) -> Dict:\n",
    "        \"\"\"主题分析\"\"\"\n",
    "        logger.info(\"开始主题分析...\")\n",
    "        # 训练LDA模型\n",
    "        lda_model, coherence = self.topic_modeling.train_lda(\n",
    "            self.processed_data['words'].tolist()\n",
    "        )\n",
    "        \n",
    "        # 训练K-means模型\n",
    "        kmeans_model, silhouette, ch_score = self.topic_modeling.train_kmeans(\n",
    "            self.processed_data['words'].tolist()\n",
    "        )\n",
    "        \n",
    "        # 获取主题词\n",
    "        topic_words = self.topic_modeling.get_topic_words()\n",
    "        \n",
    "        self.topic_results = {\n",
    "            'lda_model': lda_model,\n",
    "            'kmeans_model': kmeans_model,\n",
    "            'topic_words': topic_words,\n",
    "            'metrics': {\n",
    "                'coherence': coherence,\n",
    "                'silhouette': silhouette,\n",
    "                'ch_score': ch_score\n",
    "            }\n",
    "        }\n",
    "        return self.topic_results\n",
    "    \n",
    "    def extract_keywords(self) -> Dict[int, List[str]]:\n",
    "        \"\"\"关键词提取\"\"\"\n",
    "        logger.info(\"开始关键词提取...\")\n",
    "        # 使用两种算法提取关键词\n",
    "        tfidf_keywords = self.keyword_extractor.extract_tfidf_keywords(\n",
    "            self.processed_data['words'].tolist(),\n",
    "            self.sentiment_results[0] if self.sentiment_results else None\n",
    "        )\n",
    "        \n",
    "        textrank_keywords = self.keyword_extractor.extract_textrank_keywords(\n",
    "            self.processed_data['words'].tolist(),\n",
    "            self.sentiment_results[0] if self.sentiment_results else None\n",
    "        )\n",
    "        \n",
    "        # 合并结果\n",
    "        combined_keywords = self.keyword_extractor.combine_keywords(\n",
    "            tfidf_keywords, textrank_keywords\n",
    "        )\n",
    "        \n",
    "        self.keyword_results = combined_keywords\n",
    "        return combined_keywords\n",
    "    \n",
    "    def analyze_evolution(self) -> Dict:\n",
    "        \"\"\"演化分析\"\"\"\n",
    "        logger.info(\"开始演化分析...\")\n",
    "        \n",
    "        # 检查数据是否包含必要的列\n",
    "        required_columns = ['created_at', 'text']\n",
    "        if not all(col in self.processed_data.columns for col in required_columns):\n",
    "            raise ValueError(f\"数据中缺少必要的列: {required_columns}\")\n",
    "        \n",
    "        # 创建数据副本进行处理\n",
    "        analysis_df = self.processed_data.copy()\n",
    "        \n",
    "        # 验证created_at列的数据类型和内容\n",
    "        if not pd.api.types.is_datetime64_any_dtype(analysis_df['created_at']):\n",
    "            try:\n",
    "                # 尝试将created_at列转换为datetime格式\n",
    "                analysis_df['created_at'] = pd.to_datetime(\n",
    "                    analysis_df['created_at'], \n",
    "                    format='mixed',  # 使用混合格式解析\n",
    "                    errors='coerce'  # 将无法解析的值设为NaT\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"日期时间转换失败: {str(e)}\")\n",
    "                raise\n",
    "        \n",
    "        # 移除无效的日期时间记录\n",
    "        analysis_df = analysis_df.dropna(subset=['created_at'])\n",
    "        \n",
    "        if len(analysis_df) == 0:\n",
    "            raise ValueError(\"处理后没有有效的数据记录\")\n",
    "        \n",
    "        # 计算每日参与度\n",
    "        daily_stats = self.evolution_analyzer.calculate_daily_participation(\n",
    "            analysis_df\n",
    "        )\n",
    "        \n",
    "        # 计算对抗指数\n",
    "        confrontation_df = self.evolution_analyzer.calculate_confrontation_index(\n",
    "            analysis_df,\n",
    "            sentiment_column='sentiment'\n",
    "        )\n",
    "        \n",
    "        self.evolution_results = {\n",
    "            'daily_stats': daily_stats,\n",
    "            'confrontation': confrontation_df\n",
    "        }\n",
    "        return self.evolution_results\n",
    "    \n",
    "    def visualize(self, port: int = 8050):\n",
    "        \"\"\"启动可视化仪表盘\"\"\"\n",
    "        logger.info(\"启动可视化仪表盘...\")\n",
    "        if (self.processed_data is None or self.topic_results is None or \n",
    "            self.evolution_results is None or self.keyword_results is None):\n",
    "            raise ValueError(\"请先运行完整的分析流程\")\n",
    "        \n",
    "        dashboard = Dashboard(\n",
    "            df=self.processed_data,\n",
    "            topic_data=self.topic_results['topic_words'],\n",
    "            evolution_data=self.evolution_results['daily_stats'],\n",
    "            keyword_data=self.keyword_results\n",
    "        )\n",
    "        dashboard.run_server(port=port)\n",
    "    \n",
    "    def run(self, data_path: str):\n",
    "        \"\"\"运行完整的分析流程\"\"\"\n",
    "        # 加载数据\n",
    "        df = self.load_data(data_path)\n",
    "        \n",
    "        # 预处理\n",
    "        self.preprocess(df)\n",
    "        \n",
    "        # 情感分析\n",
    "        self.analyze_sentiment()\n",
    "        \n",
    "        # 主题分析\n",
    "        self.analyze_topics()\n",
    "        \n",
    "        # 关键词提取\n",
    "        self.extract_keywords()\n",
    "        \n",
    "        # 演化分析\n",
    "        self.analyze_evolution()\n",
    "        \n",
    "        # 保存结果\n",
    "        self.save_results()\n",
    "        \n",
    "        # 启动可视化\n",
    "        self.visualize()\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"保存分析结果\"\"\"\n",
    "        output_dir = Path(self.config['output']['dir'])\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 保存处理后的数据\n",
    "        self.processed_data.to_csv(\n",
    "            output_dir / 'processed_data.csv',\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # 保存情感分析结果\n",
    "        pd.DataFrame({\n",
    "            'text': self.processed_data['text'],\n",
    "            'sentiment': self.sentiment_results[0],\n",
    "            'probability': self.sentiment_results[1]\n",
    "        }).to_csv(output_dir / 'sentiment_results.csv', index=False)\n",
    "        \n",
    "        # 保存主题分析结果\n",
    "        pd.DataFrame(self.topic_results['topic_words']).to_csv(\n",
    "            output_dir / 'topic_results.csv'\n",
    "        )\n",
    "        \n",
    "        # 保存关键词结果\n",
    "        pd.DataFrame(self.keyword_results).to_csv(\n",
    "            output_dir / 'keyword_results.csv'\n",
    "        )\n",
    "        \n",
    "        # 保存演化分析结果\n",
    "        self.evolution_results['daily_stats'].to_csv(\n",
    "            output_dir / 'evolution_daily.csv',\n",
    "            index=False\n",
    "        )\n",
    "        self.evolution_results['confrontation'].to_csv(\n",
    "            output_dir / 'evolution_confrontation.csv',\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "def main():\n",
    "    # 创建配置文件\n",
    "    config = {\n",
    "        'preprocessing': {\n",
    "            'stopwords_path': 'data/stopwords.txt'\n",
    "        },\n",
    "        'sentiment': {\n",
    "            'model_path': 'models/sentiment_model.pt'\n",
    "        },\n",
    "        'topic': {\n",
    "            'min_topics': 2,\n",
    "            'max_topics': 10\n",
    "        },\n",
    "        'keywords': {\n",
    "            'top_k': 10\n",
    "        },\n",
    "        'output': {\n",
    "            'dir': 'output'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 保存配置文件\n",
    "    config_dir = Path('config')\n",
    "    config_dir.mkdir(exist_ok=True)\n",
    "    with open(config_dir / 'config.yaml', 'w', encoding='utf-8') as f:\n",
    "        yaml.dump(config, f, allow_unicode=True)\n",
    "    \n",
    "    # 运行Pipeline\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.run('../data/RU_Dataset_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa04852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
